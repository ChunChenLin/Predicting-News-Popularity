{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "from pandas import DataFrame\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def preprocessor(text):\n",
    "    # remove HTML tags\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    \n",
    "    # regex for matching emoticons, keep emoticons, ex: :), :-P, :-D\n",
    "    r = '(?::|;|=|X)(?:-)?(?:\\)|\\(|D|P)'\n",
    "    emoticons = re.findall(r, text)\n",
    "    text = re.sub(r, '', text)\n",
    "    \n",
    "    # convert to lowercase and append all emoticons behind (with space in between)\n",
    "    # replace('-','') removes nose of emoticons\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-','')\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenizer_stem(text):\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(word) for word in re.split('\\s+', text.strip())]\n",
    "\n",
    "def tokenizer_by_tense(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    important_words = []\n",
    "    for t in tagged:\n",
    "        tag_name = t[1][0:2]\n",
    "        word = t[0].lower()\n",
    "        if tag_name=='NN' or tag_name=='JJ' or tag_name=='VB' or tag_name=='RB':\n",
    "            porter = PorterStemmer()\n",
    "            important_words.append(word)\n",
    "        \n",
    "    return [porter.stem(w) for w in important_words if w not in stop and re.match('[a-zA-Z]+', w)]\n",
    "\n",
    "def tokenizer_stem_nostop(text):\n",
    "    porter = PorterStemmer()\n",
    "    return [porter.stem(w) for w in re.split('\\s+', text.strip()) \\\n",
    "            if w not in stop and re.match('[a-zA-Z]+', w)]\n",
    "\n",
    "df_train = pd.read_csv('datasets/train.csv')\n",
    "df_test = pd.read_csv('datasets/test.csv')\n",
    "#print(df_train.head(5))\n",
    "#print(df_test.head(5))\n",
    "page0 = df_train.loc[0,'Page content']\n",
    "#print(page0)\n",
    "df_small = df_train.sample(n=10000,random_state=0)\n",
    "#print(df_small.iloc[0]['Page content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse datetime from html\n",
    "from dateutil import parser\n",
    "\n",
    "# Extract features from raw HTML\n",
    "# Usage: \n",
    "# page0 = df.loc[0,'Page content']\n",
    "# extract_feature(page0)\n",
    "def extract_feature(html):\n",
    "    \n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # link\n",
    "    link_count = len(bs.findAll('a', href=True)) \n",
    "    \n",
    "    # image\n",
    "    img_count = len(bs.findAll('img'))\n",
    "    \n",
    "    # animation, chart or video\n",
    "    iframe_count = len(bs.findAll('iframe'))\n",
    "    \n",
    "    # quote\n",
    "    quote_count = len(bs.findAll('blockquote'))\n",
    "    \n",
    "    # tags\n",
    "    tags = [] \n",
    "    for tag in bs.select('footer a'):\n",
    "        tags.append(tag.string)\n",
    "        \n",
    "    # category\n",
    "    category = \"\"\n",
    "    for cat in bs.findAll('article'):\n",
    "        try:\n",
    "            category = cat['data-channel']\n",
    "            break\n",
    "        except:\n",
    "            category = \"\"\n",
    "            continue\n",
    "            \n",
    "    # author (seem not notable) -> discard(?)\n",
    "    '''\n",
    "    author_raw = bs.find(\"div\", { \"class\" : \"article-info\" })\n",
    "    try:\n",
    "        author = author_raw.find('a')['href']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        author = author_raw.find('span',{'class':'author_name'}).string\n",
    "    except:\n",
    "        pass\n",
    "    '''\n",
    "    \n",
    "    # title info. (h1) (must be helpful)\n",
    "    title = bs.find(\"h1\", { \"class\" : \"title\" }).string\n",
    "    title_words_count = len(re.split(r'\\s+', title))\n",
    "    title_digits_count = len([int(s) for s in title.split() if s.isdigit()])\n",
    "    title_question_mark = ('?' in title) # boolean\n",
    "    title_exclamation_mark = ('!' in title) # boolean\n",
    "    \n",
    "    # sub-title (h2) (must be helpful)\n",
    "    # count how many sub-title in the article\n",
    "    try:\n",
    "        h2 = bs.find('h2')\n",
    "        sub_title_count = len(bs.find('h2'))\n",
    "    except:\n",
    "        sub_title_count = 0\n",
    "    \n",
    "    # get word set\n",
    "    pre_text = preprocessor(html)\n",
    "    tokens = tokenizer_by_tense(pre_text)\n",
    "    total_word_count = len(tokens)\n",
    "    \n",
    "    # date\n",
    "    try:\n",
    "        datetime = bs.time['datetime']\n",
    "        l = re.split(r'\\s+', datetime)\n",
    "        weekday = re.sub(',','',l[0])\n",
    "        day = l[1]\n",
    "        month = l[2]\n",
    "        year = l[3]\n",
    "        time = l[4]\n",
    "        t = int(time.split(':')[0]) # 0~23\n",
    "        if t in [0,3]: \n",
    "            time_interval = 1 # 0~5\n",
    "        elif t in [4,7]: \n",
    "            time_interval = 2 # 6~11\n",
    "        elif t in [8,11]: \n",
    "            time_interval = 3 # 12~17\n",
    "        elif t in [12,15]:\n",
    "            time_interval = 4 # 18~23  \n",
    "        elif t in [16,19]:\n",
    "            time_interval = 5\n",
    "        else: \n",
    "            time_interval = 6\n",
    "    except:\n",
    "        weekday = ''\n",
    "        day = 0\n",
    "        month = ''\n",
    "        year = 0\n",
    "        time = 0\n",
    "        time_interval = 0\n",
    "    \n",
    "    # return \n",
    "    tmp = []\n",
    "    tmp.append(link_count)\n",
    "    tmp.append(img_count)\n",
    "    tmp.append(iframe_count)\n",
    "    tmp.append(quote_count)\n",
    "    tmp.append(tags)\n",
    "    tmp.append(category)\n",
    "    #tmp.append(author)\n",
    "    tmp.append(total_word_count)\n",
    "    \n",
    "    #tmp.append(parsed_date)\n",
    "    tmp.append(weekday)\n",
    "    tmp.append(day)\n",
    "    tmp.append(month)\n",
    "    tmp.append(year)\n",
    "    tmp.append(time)\n",
    "    tmp.append(time_interval)\n",
    "    \n",
    "    tmp.append(title_words_count)\n",
    "    tmp.append(title_digits_count)\n",
    "    tmp.append(sub_title_count)\n",
    "    tmp.append(title_question_mark)\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 29s, sys: 23.1 s, total: 27min 52s\n",
      "Wall time: 28min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# about 25min\n",
    "dsize = df_train.shape[0] #df_small.shape[0] \n",
    "dd = df_train # df_small\n",
    "link_count=[]\n",
    "img_count=[]\n",
    "iframe_count=[]\n",
    "quote_count=[]\n",
    "tags=[]\n",
    "categories=[]\n",
    "authors=[]\n",
    "total_word_count=[]\n",
    "#parsed_date=[]\n",
    "weekday=[]\n",
    "day=[]\n",
    "month=[]\n",
    "year=[]\n",
    "time=[]\n",
    "time_interval=[]\n",
    "title_words_count=[]\n",
    "title_digits_count=[]\n",
    "title_question_mark=[]\n",
    "sub_title_count=[]\n",
    "\n",
    "for i in range(dsize):\n",
    "    features = extract_feature(df_train.iloc[i]['Page content'])\n",
    "    link_count.append(features[0])\n",
    "    img_count.append(features[1])\n",
    "    iframe_count.append(features[2])\n",
    "    quote_count.append(features[3])\n",
    "    tags.append(features[4])\n",
    "    categories.append(features[5])\n",
    "    #authors.append(features[6])\n",
    "    total_word_count.append(features[6])\n",
    "    #parsed_date.append(features[8])\n",
    "    weekday.append(features[7])\n",
    "    day.append(features[8])\n",
    "    month.append(features[9])\n",
    "    year.append(features[10])\n",
    "    time.append(features[11])\n",
    "    time_interval.append(features[12])\n",
    "    title_words_count.append(features[13])\n",
    "    title_digits_count.append(features[14])\n",
    "    sub_title_count.append(features[15])\n",
    "    title_question_mark.append(features[16])\n",
    "\n",
    "d = {\n",
    "     '#link':link_count,\n",
    "     '#img':img_count,\n",
    "     '#iframe':iframe_count,\n",
    "     '#quote':quote_count,\n",
    "     #'tags':tags,\n",
    "     'categories':categories,\n",
    "     #'authors':authors,\n",
    "     '#total word':total_word_count,\n",
    "     #'date':parsed_date,\n",
    "     'weekday':weekday,\n",
    "     #'day':day,\n",
    "     #'month':month,\n",
    "     'year':year,\n",
    "     #'time':time,\n",
    "     'time interval(4hr)':time_interval,\n",
    "     '#title word':title_words_count,\n",
    "     '#title digits':title_digits_count,\n",
    "     '#sub-title':sub_title_count,\n",
    "     'If title contains \"?\"':title_question_mark,\n",
    "     'popularity':dd['Popularity'] #\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#iframe</th>\n",
       "      <th>#img</th>\n",
       "      <th>#link</th>\n",
       "      <th>#quote</th>\n",
       "      <th>#sub-title</th>\n",
       "      <th>#title digits</th>\n",
       "      <th>#title word</th>\n",
       "      <th>#total word</th>\n",
       "      <th>If title contains \"?\"</th>\n",
       "      <th>categories</th>\n",
       "      <th>popularity</th>\n",
       "      <th>time interval(4hr)</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>351</td>\n",
       "      <td>False</td>\n",
       "      <td>world</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>Wed</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>205</td>\n",
       "      <td>False</td>\n",
       "      <td>tech</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>655</td>\n",
       "      <td>False</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Wed</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>179</td>\n",
       "      <td>False</td>\n",
       "      <td>watercooler</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>994</td>\n",
       "      <td>False</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #iframe  #img  #link  #quote  #sub-title  #title digits  #title word  \\\n",
       "0        0     1     22       0           0              0            8   \n",
       "1        0     2     18       0           0              0           12   \n",
       "2       25     2     11       0           1              1           12   \n",
       "3       21     1     13       0           1              0            5   \n",
       "4        1    52     16       1           1              0           10   \n",
       "\n",
       "   #total word If title contains \"?\"     categories  popularity  \\\n",
       "0          351                 False          world          -1   \n",
       "1          205                 False           tech           1   \n",
       "2          655                 False  entertainment           1   \n",
       "3          179                 False    watercooler          -1   \n",
       "4          994                 False  entertainment          -1   \n",
       "\n",
       "   time interval(4hr) weekday  year  \n",
       "0                   4     Wed  2013  \n",
       "1                   6     Thu  2013  \n",
       "2                   5     Wed  2014  \n",
       "3                   6     Fri  2013  \n",
       "4                   1     Thu  2014  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27643, 14)\n"
     ]
    }
   ],
   "source": [
    "df = DataFrame(data=d)\n",
    "'''\n",
    "X = df.drop('popularity', 1)\n",
    "y = df['popularity']\n",
    "\n",
    "# split X into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print('#Training data points: %d' % X_train.shape[0])\n",
    "print('#Testing data points: %d' % X_test.shape[0])\n",
    "print('Class labels:', np.unique(y))\n",
    "'''\n",
    "display(df.head(5))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#iframe</th>\n",
       "      <th>#img</th>\n",
       "      <th>#link</th>\n",
       "      <th>#quote</th>\n",
       "      <th>#sub-title</th>\n",
       "      <th>#title digits</th>\n",
       "      <th>#title word</th>\n",
       "      <th>#total word</th>\n",
       "      <th>If title contains \"?\"</th>\n",
       "      <th>categories</th>\n",
       "      <th>popularity</th>\n",
       "      <th>time interval(4hr)</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>994</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #iframe  #img  #link  #quote  #sub-title  #title digits  #title word  \\\n",
       "0        0     1     22       0           0              0            8   \n",
       "1        0     2     18       0           0              0           12   \n",
       "2       25     2     11       0           1              1           12   \n",
       "3       21     1     13       0           1              0            5   \n",
       "4        1    52     16       1           1              0           10   \n",
       "\n",
       "   #total word  If title contains \"?\"  categories  popularity  \\\n",
       "0          351                      0          32          -1   \n",
       "1          205                      0          28           1   \n",
       "2          655                      0           7           1   \n",
       "3          179                      0          31          -1   \n",
       "4          994                      0           7          -1   \n",
       "\n",
       "   time interval(4hr)  weekday  year  \n",
       "0                   4        6     0  \n",
       "1                   6        4     0  \n",
       "2                   5        6     1  \n",
       "3                   6        0     0  \n",
       "4                   1        4     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27643, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode categorical features\n",
    "catego_features = ['If title contains \"?\"','categories','weekday','year']\n",
    "\n",
    "catego_le = LabelEncoder()\n",
    "\n",
    "# transform categorical values into numerical values\n",
    "# be careful that '?' will also be encoded\n",
    "# we have to replace it to NaN in numerical\n",
    "num_values = []\n",
    "for i in catego_features:\n",
    "    df[i] = catego_le.fit_transform(df[i].values)\n",
    "    classes_list = catego_le.classes_.tolist()\n",
    "    \n",
    "    # store the total number of values\n",
    "    num_values.append(len(classes_list))\n",
    "    \n",
    "    # replace '?' with 'NaN'\n",
    "    if '?' in classes_list:\n",
    "        idx = classes_list.index('?')\n",
    "        df[i] = df[i].replace(idx, np.nan)\n",
    "\n",
    "display(df.head(5))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc (10-fold cv)]\n",
      "LogisticRegression: 0.541 (+/-0.011)\n",
      "DecisionTreeClassifier: 0.510 (+/-0.009)\n",
      "RandomForestClassifier: 0.534 (+/-0.009)\n",
      "Perception: 0.504 (+/-0.020)\n",
      "SGDClassifier: 0.506 (+/-0.016)\n",
      "KNN: 0.509 (+/-0.009)\n",
      "SVC: 0.513 (+/-0.009)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# randomly sample 1000 examples\n",
    "#df_small = df_train.sample(n=1000, random_state=0)\n",
    "\n",
    "names = ['LogisticRegression', \n",
    "         'DecisionTreeClassifier',\n",
    "         'RandomForestClassifier',\n",
    "         'Perception',\n",
    "         'SGDClassifier',\n",
    "         'KNN',\n",
    "         'SVC'\n",
    "        ]\n",
    "\n",
    "# LogisticRegression\n",
    "pipe1 = Pipeline([('clf', LogisticRegression())])\n",
    "# DecisionTreeClassifier\n",
    "pipe2 = Pipeline([('clf', DecisionTreeClassifier())])\n",
    "# RandomForest\n",
    "pipe3 = Pipeline([('clf', RandomForestClassifier())])\n",
    "# Perceptron\n",
    "pipe4 = Pipeline([('clf', Perceptron())])\n",
    "# SGDClassifier\n",
    "pipe5 = Pipeline([('clf', SGDClassifier())])\n",
    "# KNN\n",
    "pipe6 = Pipeline([('clf', KNeighborsClassifier())])\n",
    "# SVC\n",
    "pipe7 = Pipeline([('clf', SVC())])\n",
    "\n",
    "# CV\n",
    "print('[auc (10-fold cv)]')\n",
    "for name, clf in zip(names, [pipe1, pipe2, pipe3, pipe4, pipe5, pipe6, pipe7]):\n",
    "    scores = cross_val_score(estimator=clf, X=df.drop('popularity', 1), y=df['popularity'], \\\n",
    "                         cv=10, scoring='roc_auc')\n",
    "    print('%s: %.3f (+/-%.3f)' % (name, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def tfidf_generator(df):\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,1),\n",
    "                        preprocessor=preprocessor,\n",
    "                        tokenizer=tokenizer_stem_nostop)\n",
    "    doc = []\n",
    "    for i in range(df.shape[0]):\n",
    "        try:\n",
    "            doc.append(df_train[df_train.Id == i].loc[i,'Page content'])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    tfidf.fit(doc)\n",
    "    doc_tfidf = tfidf.transform(doc).toarray()\n",
    "    return pd.DataFrame(doc_tfidf)\n",
    "\n",
    "#df_small_tfidf = tfidf_generator(df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.4 s, sys: 19.5 s, total: 58.9 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import optimized pickle written in C for serializing and \n",
    "# de-serializing a Python object\n",
    "import _pickle as pkl\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "df = DataFrame(data=d)\n",
    "\n",
    "# dump to disk\n",
    "pkl.dump(df, open('outputs/df.pkl', 'wb'))\n",
    "\n",
    "# load from disk\n",
    "df = pkl.load(open('outputs/df.pkl', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
